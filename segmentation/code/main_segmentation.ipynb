{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import functools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import data_io\n",
    "import u_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, losses\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_root = r'/awlab/users/chsu/WorkSpace/tensorflow/segmentation/data/plate_2017017086_ki67'\n",
    "\n",
    "img_dir = os.path.join(common_root, 'images')\n",
    "mask_dir = os.path.join(common_root, 'masks')\n",
    "\n",
    "# max_intensity = 4095.\n",
    "batch_size = 5\n",
    "# epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 388\n",
      "Number of validation samples: 98\n"
     ]
    }
   ],
   "source": [
    "x_train_fnames = sorted(glob.glob(os.path.join(img_dir,'*-2.png'))) # nucleus images\n",
    "y_train_fnames = sorted(glob.glob(os.path.join(mask_dir,'*_nucleus.png'))) # nucleus masks     \n",
    "\n",
    "\n",
    "# Split into training and validation\n",
    "x_train_fnames, x_val_fnames, y_train_fnames, y_val_fnames = \\\n",
    "    train_test_split(x_train_fnames, y_train_fnames, test_size=0.2, random_state=43)\n",
    "\n",
    "num_train_data = len(x_train_fnames)\n",
    "num_val_data = len(x_val_fnames)\n",
    "\n",
    "print(\"Number of training samples: {}\".format(num_train_data))\n",
    "print(\"Number of validation samples: {}\".format(num_val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(num_train_data)\n",
    "print(os.path.basename(x_train_fnames[idx]))\n",
    "print(os.path.basename(y_train_fnames[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image and mask from path names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(num_train_data)\n",
    "img, mask = data_io._get_image_from_path(x_train_fnames[idx], y_train_fnames[idx])\n",
    "\n",
    "plt.figure(figsize=(12,16))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,0], cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(mask))\n",
    "\n",
    "print(img.shape)\n",
    "print(img.dtype)\n",
    "print(mask.shape)\n",
    "print(img.numpy().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ds = data_io.get_dataset(x_train_fnames, y_train_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,16))\n",
    "for i, (img, mask) in enumerate(tmp_ds.shuffle(num_train_data).take(3)):\n",
    "    plt.subplot(3,2,2*i+1)\n",
    "    plt.imshow(img[0,:,:,0])\n",
    "    plt.subplot(3,2,2*i+2)\n",
    "    plt.imshow(mask[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_cfg = {\n",
    "    'resize': None, \n",
    "    'scale': 1/255.,\n",
    "    'crop_size': [512, 512],\n",
    "    'to_flip': True\n",
    "}\n",
    "tr_preproc_fn = functools.partial(data_io._augment, **train_cfg)\n",
    "\n",
    "# validation data\n",
    "val_cfg = {\n",
    "    'resize': None, \n",
    "    'scale': 1/255.,\n",
    "    'crop_size': [512, 512]\n",
    "}\n",
    "val_preproc_fn = functools.partial(data_io._augment, **val_cfg)\n",
    "\n",
    "train_ds = data_io.get_dataset(x_train_fnames, y_train_fnames, preproc_fn=tr_preproc_fn, \n",
    "                       shuffle=True, batch_size=batch_size)\n",
    "val_ds = data_io.get_dataset(x_val_fnames, y_val_fnames, preproc_fn=val_preproc_fn, \n",
    "                     shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img, mask) in val_ds.take(1):\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mask[1,:,:,0].numpy()\n",
    "plt.figure(figsize=(12,16))\n",
    "plt.imshow(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mask[1,:,:,0]\n",
    "W = balancing_weight_tf(M)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(M.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(W.numpy())\n",
    "# plt.colorbar()\n",
    "\n",
    "print(np.unique(W.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_weight(mask, scale=5):\n",
    "    wc = np.ones(mask.shape) * scale\n",
    "    wc[mask==0] = wc[mask==0] / np.sum(mask==0)\n",
    "    wc[mask==1] = wc[mask==1] / np.sum(mask==1)\n",
    "    \n",
    "    return wc\n",
    "\n",
    "def balancing_weight_tf(mask):\n",
    "    mask = tf.cast(mask, tf.bool)\n",
    "    n_ones = tf.math.count_nonzero(mask, dtype=tf.int32)\n",
    "    n_zeros = tf.size(mask, out_type=tf.int32) - n_ones\n",
    "    x = tf.ones_like(mask, dtype=tf.float32) / tf.cast(n_ones, tf.float32)\n",
    "    y = tf.ones_like(mask, dtype=tf.float32) / tf.cast(n_zeros, tf.float32)\n",
    "    wc = tf.where(mask, x, y)\n",
    "    \n",
    "    return wc\n",
    "\n",
    "def get_pixel_weights(mask):\n",
    "    scale = 3\n",
    "    w0 = 10\n",
    "    sigma = 1\n",
    "\n",
    "#     print(mask.shape)\n",
    "#     n_objs, lbl = cv2.connectedComponents(mask)\n",
    "    n_objs, lbl = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    \n",
    "    # compute distance to each object for every pixel\n",
    "    H, W = mask.shape\n",
    "    D = np.zeros([H, W, n_objs])\n",
    "    \n",
    "    for i in range(1, n_objs+1):\n",
    "        bw = np.uint8(lbl==i)\n",
    "        D[:,:,i-1] = cv2.distanceTransform(1-bw, cv2.DIST_L2, 3)\n",
    "        \n",
    "    D.sort(axis=-1)    \n",
    "    \n",
    "    # compute weight\n",
    "    wc = balancing_weight(mask, scale=scale)\n",
    "    W = wc + w0 * np.exp(-0.5 * (np.sum(D[:,:,:2], axis=-1)**2) / (sigma**2)) \n",
    "    return np.float32(W)\n",
    "    \n",
    "\n",
    "def weighted_loss(y_true, y_pred):\n",
    "#     w = tf.map_fn(lambda x: tf.numpy_function(get_pixel_weights, [x[:,:,0]], tf.float32), y_true)\n",
    "    w = tf.map_fn(lambda x: get_pixel_weights(x[:,:,0].numpy()), y_true)\n",
    "    \n",
    "#     w = tf.map_fn(balancing_weight_tf, y_true)\n",
    "#     w = tf.squeeze(w, axis=-1)\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) * w\n",
    "    \n",
    "    return loss + u_net.dice_loss(y_true, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = weighted_loss(mask, mask)\n",
    "# print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=[3, 2,2,2])\n",
    "for a in A:\n",
    "    print(a)\n",
    "    print('---')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, D = get_pixel_weights(M)\n",
    "\n",
    "\n",
    "r_rng = slice(450, 512)\n",
    "c_rng = slice(200, 250)\n",
    "plt.figure(figsize=(12,16))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(W[r_rng, c_rng])\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(M[r_rng, c_rng])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_list = [32, 64, 128, 256]\n",
    "model = u_net.Unet(num_filters_list, dynamic=True)\n",
    "model.compile(optimizer='adam', loss=weighted_loss, metrics=[u_net.dice_loss])\n",
    "\n",
    "# plt.figure(figsize=(12,16))\n",
    "# for i, (img, mask) in enumerate(train_ds.take(1)):\n",
    "#     y_pred = model(img)\n",
    "    \n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.imshow(img[0,:,:,0])\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.imshow(mask[0,:,:,0])\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(y_pred[0,:,:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = '{}'.format(datetime.datetime.now()).split('.')[0].replace(':','_').replace(' ','_')\n",
    "root_path = r'/awlab/users/chsu/WorkSpace/tensorflow/segmentation'\n",
    "\n",
    "# model weights\n",
    "weights_path = os.path.join(root_path, 'models', timestamp, 'weights-{epoch:04d}.ckpt')\n",
    "weights_dir = os.path.dirname(weights_path)\n",
    "if not os.path.isdir(weights_dir):\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=weights_path, monitor='val_dice_loss', \n",
    "                                        save_best_only=True, save_weights_only=True, verbose=1)\n",
    "# tensorboard\n",
    "log_dir = os.path.join(root_path, 'logs', timestamp)\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 10:04:27.279738 140490932487936 callbacks.py:1218] TensorBoard Callback will ignore `write_graph=True`when `Model.run_eagerly=True`.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=30, \n",
    "                    steps_per_epoch=int(np.ceil(num_train_data / batch_size)),\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=int(np.ceil(num_val_data / batch_size)),\n",
    "                    callbacks=[cp, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(u_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in train_ds.take(1):\n",
    "    u_net.bce_dice_loss(y,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_process = pd.DataFrame.from_dict(history.history)\n",
    "tr_process['epoch'] = np.array(range(1, tr_process.shape[0]+1))\n",
    "\n",
    "tr_process.plot(x='epoch', y=['loss', 'val_loss'])\n",
    "tr_process.plot(x='epoch', y=['dice_loss', 'val_dice_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'/awlab/users/chsu/WorkSpace/tensorflow/segmentation/models/2019-04-05_14_15_41'\n",
    "latest = tf.train.latest_checkpoint(model_dir)\n",
    "print(latest)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask(img, mask, mask_pred):\n",
    "    \"\"\"green: true, red: predicted\"\"\"\n",
    "    I = np.uint8(img.numpy()*255.)\n",
    "    I = cv2.cvtColor(I,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    M = np.uint8(mask.numpy()*255.)\n",
    "    M_pred = np.uint8((mask_pred.numpy()>0.5) * 255.)\n",
    "    \n",
    "    im, contours, _ = cv2.findContours(M.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    im_pred, contours_pred, _ = cv2.findContours(M_pred.copy(), \n",
    "                                                cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    I1 = cv2.drawContours(I.copy(), contours, -1, (0,255,0), 1)\n",
    "    I2 = cv2.drawContours(I.copy(), contours_pred, -1, (255,0,0), 1)\n",
    "    I[:,:,1] = I1[:,:,1]\n",
    "    I[:,:,0] = I2[:,:,0]\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_plot = np.random.choice(num_val_data, 3)\n",
    "result_folder = r'/awlab/users/chsu/WorkSpace/tensorflow/segmentation/results'\n",
    "\n",
    "if not os.path.isdir(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "\n",
    "# plt.figure(figsize=(12,16))\n",
    "\n",
    "for i, (img, mask) in enumerate(val_ds):\n",
    "    if i in idx_to_plot:\n",
    "        y_pred = model(img)        \n",
    "        for j in range(4):\n",
    "            I = overlay_mask(img[j,:,:,0], mask[j,:,:,0], y_pred[j,:,:,0])\n",
    "            fname = os.path.join(result_folder, '{}_{}.png'.format(i,j))\n",
    "            cv2.imwrite(fname, cv2.cvtColor(I, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "#             plt.subplot(2,2,j+1)\n",
    "#             plt.imshow(I)\n",
    "            \n",
    "    if i > max(idx_to_plot):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
