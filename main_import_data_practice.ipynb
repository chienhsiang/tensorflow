{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source -> Tranformation -> Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))\n",
    "\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random_uniform([4]),\n",
    "     tf.random_uniform([4, 100], maxval=100, dtype=tf.float32)))\n",
    "\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\"a\": tf.random_uniform([4]),\n",
    "     \"b\": tf.random_uniform([4, 100], maxval=100)})\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset2.map(lambda x, y: (x+2+y*2))\n",
    "\n",
    "print(dataset2.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-shot\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(100):\n",
    "        value = sess.run(next_element)\n",
    "        assert i == value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializable iterator\n",
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={max_value: 10})    \n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(value)\n",
    "        \n",
    "    sess.run(iterator.initializer, feed_dict={max_value: 30})    \n",
    "    for i in range(40):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitializable iterator\n",
    "training_dataset = tf.data.Dataset.range(100).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, dtype=tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "epochs = 20\n",
    "with tf.Session() as sess:\n",
    "    for i in range(epochs):\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(100):\n",
    "            sess.run(next_element)\n",
    "\n",
    "        sess.run(validation_init_op)\n",
    "        for _ in range(50):\n",
    "            sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedable iterator\n",
    "training_dataset = tf.data.Dataset.range(100).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, dtype=tf.int64)).repeat()\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_itertor = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_itertor.string_handle())\n",
    "      \n",
    "    for _ in range(50):\n",
    "        for _ in range(200):\n",
    "            sess.run(next_element, feed_dict={handle: training_handle})\n",
    "        \n",
    "        sess.run(validation_itertor.initializer)\n",
    "        for _ in range(50):\n",
    "            sess.run(next_element, feed_dict={handle: validation_handle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "# Consuming values from an iterator\n",
    "dataset = tf.data.Dataset.range(5)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "result = tf.add(next_element, next_element) # this two next_elements are the same\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(result))\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")\n",
    "            break\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching dataset\n",
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "dataset_batch = dataset.batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3]), array([ 0, -1, -2, -3]))\n",
      "(array([4, 5, 6, 7]), array([-4, -5, -6, -7]))\n",
      "(array([ 8,  9, 10, 11]), array([ -8,  -9, -10, -11]))\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset_batch.make_one_shot_iterator()\n",
    "next_ = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_))\n",
    "    print(sess.run(next_))\n",
    "    print(sess.run(next_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching with padding\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "dataset = dataset.padded_batch(4, padded_shapes=[None])\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_ = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_))\n",
    "    print(sess.run(next_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
