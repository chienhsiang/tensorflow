{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfcontrib\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_kaggle_credentials():\n",
    "    token_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
    "    token_file = os.path.join(token_dir, \"kaggle.json\")\n",
    "    if not os.path.isdir(token_dir):\n",
    "        os.mkdir(token_dir)\n",
    "    try:\n",
    "        with open(token_file,'r') as f:\n",
    "            pass\n",
    "    except IOError as no_file:\n",
    "        try:\n",
    "            from google.colab import files\n",
    "        except ImportError:\n",
    "            raise no_file\n",
    "\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        if \"kaggle.json\" not in uploaded:\n",
    "            raise ValueError(\"You need an API key! see:\"\n",
    "                             \"https://github.com/Kaggle/kaggle-api#api-credentials\")\n",
    "        with open(token_file, \"wb\") as f:\n",
    "            f.write(uploaded[\"kaggle.json\"])\n",
    "        os.chmod(token_file, 600)\n",
    "\n",
    "get_kaggle_credentials()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_name = 'carvana-image-masking-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_zip(competition, file):\n",
    "    with zipfile.ZipFile(os.path.join(competition, file), \"r\") as zip_ref:\n",
    "        unzipped_file = zip_ref.namelist()[0]\n",
    "        zip_ref.extractall(competition)\n",
    "        \n",
    "def get_data(competition):\n",
    "    kaggle.api.competition_download_files(competition, competition)\n",
    "    load_data_from_zip(competition, 'train.zip')\n",
    "    load_data_from_zip(competition, 'train_masks.zip')\n",
    "    load_data_from_zip(competition, 'train_masks.csv.zip')\n",
    "\n",
    "get_data(competition_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(competition_name, \"train\")\n",
    "label_dir = os.path.join(competition_name, \"train_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(competition_name, 'train_masks.csv'))\n",
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames = []\n",
    "y_train_filenames = []\n",
    "for img_id in ids_train:\n",
    "    x_train_filenames.append(os.path.join(img_dir, \"{}.jpg\".format(img_id)))\n",
    "    y_train_filenames.append(os.path.join(label_dir, \"{}_mask.gif\".format(img_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = train_test_split(\n",
    "    x_train_filenames, y_train_filenames, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = len(x_train_filenames)\n",
    "num_val_examples = len(x_val_filenames)\n",
    "\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of validation examples: {}\".format(num_val_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_num = 5\n",
    "\n",
    "r_choice = np.random.choice(num_train_examples, display_num)\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "for i in range(0, display_num*2, 2):\n",
    "    idx = i // 2\n",
    "    x_path = x_train_filenames[idx]\n",
    "    y_path = y_train_filenames[idx]\n",
    "    \n",
    "    plt.subplot(display_num, 2, i+1)\n",
    "    plt.imshow(plt.imread(x_path))\n",
    "    plt.title(\"Original Image\")\n",
    "    \n",
    "    plt.subplot(display_num, 2, i+2)\n",
    "    plt.imshow(plt.imread(y_path))\n",
    "    plt.title(\"Masked Image\")\n",
    "    \n",
    "#     example_labels = Image.open(y_path)\n",
    "#     label_vals = np.unique(example_labels)  \n",
    "#     plt.subplot(display_num, 2, i + 2)\n",
    "#     plt.imshow(example_labels)\n",
    "#     plt.title(\"Masked Image\") \n",
    "\n",
    "plt.suptitle(\"Examples of Images and Masks\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (256, 256, 3)\n",
    "batch_size = 3\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert each file name to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_pathnames(fname, label_path):\n",
    "    \"\"\"Convet input file name amd label path into image and mask.\"\"\"\n",
    "    img = tf.image.decode_jpeg(tf.read_file(fname), channels=3)\n",
    "    label_img = tf.image.decode_gif(tf.read_file(label_path))[0]\n",
    "    label_img = tf.expand_dims(label_img[:,:,0], axis=-1)\n",
    "    return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = _process_pathnames(x_train_filenames[5], y_train_filenames[5])\n",
    "\n",
    "print(img.shape, mask.shape)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask[:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tfcontrib.image.translate(img, [500, 500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_img(output_img, label_img, width_shift_range, height_shift_range):\n",
    "    if width_shift_range or height_shift_range:\n",
    "        # randomly select a number from [-shift, shift]\n",
    "        if width_shift_range:\n",
    "            width_shift_range = tf.random_uniform([], minval=-img_shape[1]*width_shift_range,\n",
    "                                                 maxval=img_shape[1]*width_shift_range)\n",
    "            \n",
    "        if height_shift_range:\n",
    "            height_shift_range = tf.random_uniform([], minval=-img_shape[0]*height_shift_range,\n",
    "                                                 maxval=img_shape[0]*height_shift_range)\n",
    "            \n",
    "        output_img = tfcontrib.image.translate(output_img, [width_shift_range, height_shift_range])\n",
    "        label_img = tfcontrib.image.translate(label_img, [width_shift_range, height_shift_range])\n",
    "        \n",
    "    return output_img, label_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2, mask2 = shift_img(tf.image.resize(img, img_shape[:-1]), tf.image.resize(mask, img_shape[:-1]), 0.5, 0.5)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img2/255)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask2[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping the image randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_img(horizontal_flip, tr_img, label_img):\n",
    "    \"\"\"Flip the image and mask at the probability of 0.5\"\"\"    \n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "        tr_img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                    lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),\n",
    "                                    lambda: (tr_img, label_img))\n",
    "        \n",
    "#         to_flip = tf.random_uniform([], 0.0, 1.0).numpy() > 0.5\n",
    "\n",
    "#         if to_flip:\n",
    "#             tr_img = tf.image.flip_left_right(tr_img)\n",
    "#             label_img = tf.image.flip_left_right(label_img)\n",
    "        \n",
    "    return tr_img, label_img\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2, mask2 = flip_img(True, img, mask)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask2[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble into the augment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _augment(img, label_img,\n",
    "             resize=None,\n",
    "             scale=1,\n",
    "             hue_delta=0,\n",
    "             horizontal_flip=False,\n",
    "             width_shift_range=0,\n",
    "             height_shift_range=0):\n",
    "    if resize is not None:\n",
    "        # resize both image and mask\n",
    "        img = tf.image.resize(img, resize)\n",
    "        label_img = tf.image.resize(label_img, resize)\n",
    "        \n",
    "    if hue_delta:\n",
    "        img = tf.image.random_hue(img, hue_delta)\n",
    "        \n",
    "        \n",
    "    img, label_img = flip_img(horizontal_flip, img, label_img)\n",
    "    img, label_img = shift_img(img, label_img, width_shift_range, height_shift_range)\n",
    "    \n",
    "    img = tf.to_float(img) * scale\n",
    "    label_img = tf.to_float(label_img) * scale\n",
    "    \n",
    "    return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2, mask2 = _augment(img, mask, resize=img_shape[:-1], scale=1/255.0, hue_delta=0.2, horizontal_flip=True,\n",
    "                      width_shift_range=0.5, height_shift_range=0.3)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask2[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_dataset(filenames, labels, preproc_fn=functools.partial(_augment),\n",
    "                         threads=5, batch_size=batch_size, shuffle=True):\n",
    "    \"\"\"Create a TF Dataset from filenames\"\"\"\n",
    "    num_x = len(filenames)\n",
    "    \n",
    "    # 1. Create a dataset of filenames\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    \n",
    "    # 2. Convert filenames into images\n",
    "    dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "    \n",
    "    # 3. Augment data\n",
    "    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
    "        assert batch_size == 1, \"\"\"Batching images must be of the same size\"\"\"\n",
    "        \n",
    "    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset.shuffle(num_x)\n",
    "        \n",
    "    return dataset.repeat().batch(batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1/255.0,\n",
    "    'hue_delta': 0.1,\n",
    "    'horizontal_flip': True,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1    \n",
    "}\n",
    "\n",
    "tr_preproc_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1/255.0,\n",
    "}\n",
    "val_preproc_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_baseline_dataset(x_train_filenames, y_train_filenames, preproc_fn=tr_preproc_fn, batch_size=batch_size)\n",
    "val_ds = get_baseline_dataset(x_val_filenames, y_val_filenames, preproc_fn=val_preproc_fn, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = get_baseline_dataset(x_train_filenames, y_train_filenames, preproc_fn=tr_preproc_fn,\n",
    "                              batch_size=1, shuffle=False)\n",
    "n_x = len(x_train_filenames)\n",
    "for i, x in enumerate(temp_ds.take(6)):\n",
    "    if i is 0:        \n",
    "        plt.subplot(2,2,1)\n",
    "        plt.imshow(x[0][0,:,:,:])\n",
    "        plt.subplot(2,2,2)\n",
    "        plt.imshow(x[1][0,:,:,0])\n",
    "        \n",
    "    if i is 5:\n",
    "        plt.subplot(2,2,3)\n",
    "        plt.imshow(x[0][0,:,:,:])\n",
    "        plt.subplot(2,2,4)\n",
    "        plt.imshow(x[1][0,:,:,0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    \"\"\"Two conv with batch normalization\"\"\"\n",
    "    encoder = layers.Conv2D(num_filters, (3,3), padding='same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3,3), padding='same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(encoder)\n",
    "    \n",
    "    return encoder_pool, encoder\n",
    "\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    \n",
    "    decoder = conv_block(decoder, num_filters)\n",
    "#     decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "#     decoder = layers.BatchNormalization()(decoder)\n",
    "#     decoder = layers.Activation('relu')(decoder)\n",
    "#     decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "#     decoder = layers.BatchNormalization()(decoder)\n",
    "#     decoder = layers.Activation('relu')(decoder)\n",
    "    \n",
    "    return decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the U-net\n",
    "inputs = layers.Input(shape=img_shape)\n",
    "# 256\n",
    "\n",
    "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
    "# 128\n",
    "\n",
    "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
    "# 64\n",
    "\n",
    "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
    "# 32\n",
    "\n",
    "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
    "# 16\n",
    "\n",
    "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
    "# 8\n",
    "\n",
    "# center\n",
    "center_tensor = conv_block(encoder4_pool, 1024)\n",
    "\n",
    "decoder4 = decoder_block(center_tensor, encoder4, 512)\n",
    "# 16\n",
    "\n",
    "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "# 32\n",
    "\n",
    "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "# 64\n",
    "\n",
    "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "# 128\n",
    "\n",
    "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
    "# 256\n",
    "\n",
    "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define losses and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true = tf.reshape(y_true, shape=[-1])\n",
    "    y_pred = tf.reshape(y_pred, shape=[-1])\n",
    "    \n",
    "    intersect = tf.reduce_sum(y_true * y_pred)\n",
    "    score = (2. * intersect + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coeff(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_loss])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'/awlab/users/chsu/WorkSpace/tensorflow/tmp/weights.h5'\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor='val_dice_loss', \n",
    "                                        save_best_only=True, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=1, steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n",
    "                    validation_data=val_ds, callbacks=[cp], \n",
    "                    validation_steps=int(np.ceil(num_val_examples / float(batch_size))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = history.history['dice_loss']\n",
    "val_dice = history.history['val_dice_loss']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, dice, label='Training Dice Loss')\n",
    "plt.plot(epochs_range, val_dice, label='Validation Dice Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Dice Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize actual performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, (img_batch, label_batch)) in enumerate(val_ds.take(5)):\n",
    "    idx = 2\n",
    "    img = img_batch[idx]\n",
    "    label = label_batch[idx]\n",
    "    label_pred = model(img_batch)[idx]\n",
    "    \n",
    "    plt.figure(figsize=(10,15))\n",
    "    plt.subplot(5, 3, 3 * i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(5, 3, 3 * i + 2)\n",
    "    plt.imshow(label[:,:,0])\n",
    "    plt.subplot(5, 3, 3 * i + 3)\n",
    "    plt.imshow(label_pred[:,:,0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
